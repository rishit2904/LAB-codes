{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Lab 7 - Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model with optimizer weight decay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/Documents/220962436_Keshav/dllab/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, loss = 0.7828\n",
      "epoch 2/10, loss = 0.6043\n",
      "epoch 3/10, loss = 0.5477\n",
      "epoch 4/10, loss = 0.4663\n",
      "epoch 5/10, loss = 0.3704\n",
      "epoch 6/10, loss = 0.2686\n",
      "epoch 7/10, loss = 0.1975\n",
      "epoch 8/10, loss = 0.1201\n",
      "epoch 9/10, loss = 0.0691\n",
      "epoch 10/10, loss = 0.0379\n",
      "training model with manual L2 regularization...\n",
      "epoch 1/10, loss with l2 penalty = 1.8940\n",
      "epoch 2/10, loss with l2 penalty = 1.8402\n",
      "epoch 3/10, loss with l2 penalty = 1.7920\n",
      "epoch 4/10, loss with l2 penalty = 1.7462\n",
      "epoch 5/10, loss with l2 penalty = 1.7018\n",
      "epoch 6/10, loss with l2 penalty = 1.6587\n",
      "epoch 7/10, loss with l2 penalty = 1.6170\n",
      "epoch 8/10, loss with l2 penalty = 1.5765\n",
      "epoch 9/10, loss with l2 penalty = 1.5369\n",
      "epoch 10/10, loss with l2 penalty = 1.4985\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/train\", transform=transform)\n",
    "test_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/validation\", transform=transform)\n",
    "\n",
    "train_loader=data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=data.DataLoader(test_dataset,batch_size=32,shuffle=False)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,1),\n",
    "            nn.Conv2d(16,32,3,1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124*124*32,512),\n",
    "            nn.Linear(512,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def train_weight_decay(model,train_loader,criterion,optimizer,epochs,loss_list):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0.0\n",
    "\n",
    "        for images,labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs=model(images)\n",
    "            loss=criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+=loss.item()\n",
    "\n",
    "        loss_list.append(epoch_loss/len(train_loader))\n",
    "        print(f\"epoch {epoch+1}/{epochs}, loss = {loss_list[-1]:.4f}\")\n",
    "\n",
    "def train_manual(model, train_loader, criterion, optimizer, epochs, loss_list, lambda_l2=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs=model(images)\n",
    "            loss=criterion(outputs, labels)\n",
    "\n",
    "            l2_penalty=0\n",
    "            for param in model.parameters():\n",
    "                l2_penalty+=torch.sum(param**2)\n",
    "\n",
    "            total_loss=loss+lambda_l2*l2_penalty\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+=total_loss.item()\n",
    "\n",
    "        loss_list.append(epoch_loss / len(train_loader))\n",
    "        print(f\"epoch {epoch + 1}/{epochs}, loss with l2 penalty = {loss_list[-1]:.4f}\")\n",
    "\n",
    "model=CNN()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_weight_decay=optim.SGD(model.parameters(),lr=0.01,weight_decay=0.001)\n",
    "optimizer_no_weight_decay=optim.SGD(model.parameters(),lr=0.01)\n",
    "epochs=10\n",
    "loss_wd=[]\n",
    "loss_manual=[]\n",
    "\n",
    "print(\"training model with optimizer weight decay...\")\n",
    "train_weight_decay(model,train_loader,criterion,optimizer_weight_decay,epochs,loss_wd)\n",
    "\n",
    "print(\"training model with manual L2 regularization...\")\n",
    "train_manual(model,train_loader,criterion,optimizer_weight_decay,epochs,loss_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model with manual L1 regularization...\n",
      "epoch 1/2, loss with L1 penalty = 264.0457, accuracy = 51.50%\n",
      "epoch 2/2, loss with L1 penalty = 128.6703, accuracy = 52.50%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/train\", transform=transform)\n",
    "test_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/validation\", transform=transform)\n",
    "\n",
    "train_loader=data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=data.DataLoader(test_dataset,batch_size=32,shuffle=False)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,1),\n",
    "            nn.Conv2d(16,32,3,1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124*124*32,512),\n",
    "            nn.Linear(512,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_manual(model, train_loader, criterion, optimizer, epochs, loss_list, lambda_l1=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0.0\n",
    "\n",
    "        total_correct=0\n",
    "        total_samples=0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs=model(images)\n",
    "            loss=criterion(outputs, labels)\n",
    "\n",
    "            l1_penalty=0\n",
    "            for param in model.parameters():\n",
    "                l1_penalty+=torch.sum(torch.abs(param))\n",
    "\n",
    "            total_loss=loss+lambda_l1*l1_penalty\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+=total_loss.item()\n",
    "\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct+=(predicted==labels).sum().item()\n",
    "\n",
    "        accuracy=100*total_correct/total_samples\n",
    "        loss_list.append(epoch_loss / len(train_loader))\n",
    "        print(f\"epoch {epoch + 1}/{epochs}, loss with L1 penalty = {loss_list[-1]:.4f}, accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "model=CNN()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_weight_decay=optim.SGD(model.parameters(),lr=0.01,weight_decay=0.001)\n",
    "optimizer_no_weight_decay=optim.SGD(model.parameters(),lr=0.01)\n",
    "epochs=2\n",
    "loss_manual=[]\n",
    "\n",
    "print(\"training model with manual L1 regularization...\")\n",
    "train_manual(model,train_loader,criterion,optimizer_weight_decay,epochs,loss_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model with dropout regularization...\n",
      "epoch 1/2, loss = 0.7985, accuracy = 55.20%\n",
      "epoch 2/2, loss = 0.5857, accuracy = 70.90%\n",
      "training model without dropout regularization...\n",
      "epoch 1/2, loss = 0.6932, accuracy = 52.60%\n",
      "epoch 2/2, loss = 0.6929, accuracy = 52.60%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/train\", transform=transform)\n",
    "test_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/validation\", transform=transform)\n",
    "\n",
    "train_loader=data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=data.DataLoader(test_dataset,batch_size=32,shuffle=False)\n",
    "\n",
    "train_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/train\", transform=transform)\n",
    "test_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/validation\", transform=transform)\n",
    "\n",
    "train_loader=data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=data.DataLoader(test_dataset,batch_size=32,shuffle=False)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,with_dropout=True):\n",
    "        super(CNN,self).__init__()\n",
    "        if with_dropout:\n",
    "            self.net=nn.Sequential(\n",
    "                nn.Conv2d(3,16,3,1),\n",
    "                nn.Conv2d(16,32,3,1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(124*124*32,512),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512,2)\n",
    "            )\n",
    "        else:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, 3, 1),\n",
    "                nn.Conv2d(16, 32, 3, 1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(124 * 124 * 32, 512),\n",
    "                nn.Linear(512, 2)\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "def epoch_train(model, train_loader, criterion, optimizer, epochs, loss_list, lambda_l1=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0.0\n",
    "\n",
    "        total_correct=0\n",
    "        total_samples=0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs=model(images)\n",
    "            loss=criterion(outputs, labels)\n",
    "\n",
    "            l1_penalty=0\n",
    "            for param in model.parameters():\n",
    "                l1_penalty+=torch.sum(torch.abs(param))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+=loss.item()\n",
    "\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct+=(predicted==labels).sum().item()\n",
    "\n",
    "        accuracy=100*total_correct/total_samples\n",
    "        loss_list.append(epoch_loss / len(train_loader))\n",
    "        print(f\"epoch {epoch + 1}/{epochs}, loss = {loss_list[-1]:.4f}, accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "model_dropout=CNN(with_dropout=True)\n",
    "model_no_dropout=CNN(with_dropout=False)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer=optim.SGD(model_dropout.parameters(),lr=0.01)\n",
    "\n",
    "epochs=2\n",
    "loss_manual=[]\n",
    "\n",
    "print(\"training model with dropout regularization...\")\n",
    "epoch_train(model_dropout,train_loader,criterion,optimizer,epochs,loss_manual)\n",
    "\n",
    "print(\"training model without dropout regularization...\")\n",
    "epoch_train(model_no_dropout,train_loader,criterion,optimizer,epochs,loss_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training custom model with custom dropout...\n",
      "epoch 1/5, loss: 0.8576, accuracy: 54.10%\n",
      "epoch 2/5, loss: 0.6170, accuracy: 65.95%\n",
      "epoch 3/5, loss: 0.5525, accuracy: 73.20%\n",
      "epoch 4/5, loss: 0.4786, accuracy: 78.90%\n",
      "epoch 5/5, loss: 0.3835, accuracy: 85.20%\n",
      "training model with built-in dropout...\n",
      "epoch 1/5, loss: 0.8435, accuracy: 56.70%\n",
      "epoch 2/5, loss: 0.6048, accuracy: 67.30%\n",
      "epoch 3/5, loss: 0.5326, accuracy: 74.65%\n",
      "epoch 4/5, loss: 0.4619, accuracy: 80.00%\n",
      "epoch 5/5, loss: 0.3630, accuracy: 85.15%\n",
      "\n",
      "testing custom model with custom dropout...\n",
      "custom model accuracy: 56.00%\n",
      "\n",
      "testing model with built-in dropout...\n",
      "built-in model accuracy: 55.30%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"./cats_and_dogs_filtered/train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=\"./cats_and_dogs_filtered/validation\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class CustomDropout(nn.Module):\n",
    "    def __init__(self,rate):\n",
    "        super(CustomDropout,self).__init__()\n",
    "        self.rate=rate\n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.training:\n",
    "            mask=(torch.rand_like(x)<(1-self.rate)).float()\n",
    "            x=x*mask/(1-self.rate)\n",
    "        return x\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,1),\n",
    "            CustomDropout(0.5),\n",
    "            nn.Conv2d(16,32,3,1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124*124*32,512),\n",
    "            nn.Linear(512,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class BuiltInCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BuiltInCNN,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(16,32,3,1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124*124*32,512),\n",
    "            nn.Linear(512,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        print(f\"epoch {epoch + 1}/{epochs}, loss: {epoch_loss / len(train_loader):.4f}, accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "custom_model=CustomCNN()\n",
    "builtin_model=BuiltInCNN()\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer_custom = optim.SGD(custom_model.parameters(), lr=0.01)\n",
    "optimizer_builtin = optim.SGD(builtin_model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 5\n",
    "print(\"training custom model with custom dropout...\")\n",
    "train(custom_model, train_loader, criterion, optimizer_custom, epochs)\n",
    "\n",
    "print(\"training model with built-in dropout...\")\n",
    "train(builtin_model, train_loader, criterion, optimizer_builtin, epochs)\n",
    "\n",
    "print(\"\\ntesting custom model with custom dropout...\")\n",
    "custom_model_accuracy = test(custom_model, test_loader)\n",
    "print(f\"custom model accuracy: {custom_model_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\ntesting model with built-in dropout...\")\n",
    "builtin_model_accuracy = test(builtin_model, test_loader)\n",
    "print(f\"built-in model accuracy: {builtin_model_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model with early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/Documents/220962436_Keshav/dllab/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, train loss: 0.8051, validation loss: 0.6765, accuracy: 58.80%\n",
      "epoch 2/10, train loss: 0.6031, validation loss: 0.6733, accuracy: 59.30%\n",
      "epoch 3/10, train loss: 0.5330, validation loss: 0.7581, accuracy: 57.10%\n",
      "epoch 4/10, train loss: 0.4364, validation loss: 0.7765, accuracy: 56.20%\n",
      "epoch 5/10, train loss: 0.3299, validation loss: 0.9492, accuracy: 56.00%\n",
      "early stopping at epoch 5\n",
      "\n",
      "training model without early stopping...\n",
      "epoch 1/10, train loss: 0.7753, validation loss: 0.6992, accuracy: 58.30%\n",
      "epoch 2/10, train loss: 0.5901, validation loss: 0.6899, accuracy: 56.40%\n",
      "epoch 3/10, train loss: 0.5062, validation loss: 0.7657, accuracy: 56.50%\n",
      "epoch 4/10, train loss: 0.4204, validation loss: 0.8097, accuracy: 56.50%\n",
      "epoch 5/10, train loss: 0.3272, validation loss: 1.0154, accuracy: 55.00%\n",
      "epoch 6/10, train loss: 0.2245, validation loss: 1.2001, accuracy: 55.70%\n",
      "epoch 7/10, train loss: 0.1460, validation loss: 1.3875, accuracy: 52.20%\n",
      "epoch 8/10, train loss: 0.0934, validation loss: 1.6448, accuracy: 52.10%\n",
      "epoch 9/10, train loss: 0.0515, validation loss: 1.6743, accuracy: 55.60%\n",
      "epoch 10/10, train loss: 0.0287, validation loss: 1.8507, accuracy: 54.70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/train\", transform=transform)\n",
    "test_dataset=datasets.ImageFolder(root=\"./cats_and_dogs_filtered/validation\", transform=transform)\n",
    "\n",
    "train_loader=data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader=data.DataLoader(test_dataset,batch_size=32,shuffle=False)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,1),\n",
    "            nn.Conv2d(16,32,3,1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124*124*32,512),\n",
    "            nn.Linear(512,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_es(model,train_loader, val_loader,criterion,optimizer,epochs, patience):\n",
    "    best_val_loss=float(\"inf\")\n",
    "    static_epochs=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs=model(images)\n",
    "            loss=criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+=loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss=0.0\n",
    "        total_correct=0\n",
    "        total_samples=0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs=model(images)\n",
    "                loss=criterion(outputs,labels)\n",
    "                val_loss+=loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        print(f\"epoch {epoch + 1}/{epochs}, train loss: {epoch_loss / len(train_loader):.4f}, validation loss: {val_loss:.4f}, accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss=val_loss\n",
    "            static_epochs=0\n",
    "        else:\n",
    "            static_epochs+=1\n",
    "\n",
    "        if static_epochs>=patience:\n",
    "            print(f\"early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "def train_no_es(model, train_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        print(f\"epoch {epoch+1}/{epochs}, train loss: {epoch_loss/len(train_loader):.4f}, validation loss: {val_loss:.4f}, accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "model_es=CNN()\n",
    "model_no_es=CNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_with_early_stopping = optim.SGD(model_es.parameters(), lr=0.01)\n",
    "optimizer_without_early_stopping = optim.SGD(model_no_es.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "patience = 3  # Number of epochs to wait before stopping if no improvement in validation loss\n",
    "\n",
    "print(\"training model with early stopping...\")\n",
    "train_es(model_es, train_loader, test_loader, criterion, optimizer_with_early_stopping, epochs, patience)\n",
    "\n",
    "print(\"\\ntraining model without early stopping...\")\n",
    "train_no_es(model_no_es, train_loader, criterion, optimizer_without_early_stopping, epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "dllab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
